---
title: "countcheck"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{countcheck}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(countcheck)
```

## Detecting Count Anomalies Using Bayesian Hierarchical Models

Prototype (R package).

* Dertermines upper control limits for count data
* Reasonable results also in cases with few or no observed events
* HTML reports

Model and code are based on examples in 
[McElreath (2020)](https://xcelab.net/rm/statistical-rethinking/) and
[Gelman et al. (2014)](https://www.stat.columbia.edu/~gelman/book/).

This prototype is related to a previous 
[simulation study](https://jmeydam.github.io/count-anomalies/simulation_study.html).

The distributions and parameters in the simulation study were chosen
so that the generated data is comparable to certain data of interest.
The prototype is meant to be used for roughly the same kind of data. 
Please refer to the
[report](https://jmeydam.github.io/count-anomalies/simulation_study.html) 
for details.

The package documentation can be accessed via the 
[package website](https://jmeydam.github.io/countcheck/).

## Installation

First install dependencies:

* actuar
* extraDistr
* rstan ([instructions](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started))
* rethinking (>= 2.01)

The rethinking package needs to be installed from 
[GitHub](https://github.com/rmcelreath/rethinking).

The prototype can then be installed from GitHub with:
```
devtools::install_github("https://github.com/jmeydam/countcheck.git", 
                         build_vignettes = FALSE)
```

## Example 1

Count data for 1000 observational units are simulated, assuming a "normal"
data-generating process.

Since the data-generating process is free of anomalies, all counts exceeding 
their respective upper control limits (UCLs) are false positives. Other things 
being equal it is desirable to have as few false positives as possible.

Using a Bayesian hierarchical model with partial pooling, 18 new counts exceed
their respective upper control limits, vs. 68 when using a no-pooling 
model. (4 counts exceed the UCLs based on the true value of the parameter 
_theta_, which is known in this case.)


```{r}
d <- countcheck(random_seed = 200807)
```

Result:

```{r}

# Counts exceeding UCLs
# *********************
# ucl_true_theta:
sum(d$y_new - d$ucl_true_theta > 0)
# ucl_nopool:
sum(d$y_new - d$ucl_nopool > 0)
# ucl_complpool:
sum(d$y_new - d$ucl_complpool > 0)
# ucl_partpool:
sum(d$y_new - d$ucl_partpool > 0)

d[d$y_new - d$ucl_partpool > 0,
  c("n", "y", "n_new", "y_new",
    "true_theta", "theta_partpool",
    "ucl_true_theta", "ucl_partpool")]
```

### Alternatively:

Using the dataset provided in the package, the same result (here without the 
true_theta values) can be obtained with:

```{r}
e <- simdat
d1 <- countcheck(unit = e$unit,
                 n = e$n,
                 y = e$y,
                 n_new = e$n_new,
                 y_new = e$y_new,
                 random_seed = 200807)
```

Result:

```{r}
d1[d1$y_new - d1$ucl_partpool > 0,
   c("n", "y", "n_new", "y_new",
     "true_theta", "theta_partpool",
     "ucl_true_theta", "ucl_partpool")]
```
## Example 2

The count data in the first example were simulated with a known, "normal"
data-generating process. Some new count values of interest _y_new_ were 0.

In this example we change _y_new_ as follows:

`y_new = round(2 * ceiling(e$n_new * e$true_theta))`

This is essentially twice the expected value for _y_new_, given a new 
reference count value n_new (used as a measure of exposure) and a value 
for _theta_. We round the result up, and the lowest possible value in 
this example is 1.

Since we use a factor of 2, it is likely that the product will often
exceed the upper control limit (UCL).

Using a Bayesian hierarchical model with partial pooling, 332 new counts exceed
their respective upper control limits, vs. 489 when using a no-pooling 
model. 310 counts exceed the UCLs based on the true value of the parameter 
_theta_, which is known in this case.

```{r}
d2 <- countcheck(unit = e$unit,
                 n = e$n,
                 y = e$y,
                 n_new = e$n_new,
                 y_new = round(2 * ceiling(e$n_new * e$true_theta)),
                 true_theta = e$true_theta,
                 random_seed = 200807)
```

Result:

```{r}
# Counts exceeding UCLs
# *********************
# ucl_true_theta:
sum(d2$y_new - d2$ucl_true_theta > 0)
# ucl_nopool:
sum(d2$y_new - d2$ucl_nopool > 0)
# ucl_complpool:
sum(d2$y_new - d2$ucl_complpool > 0)
# ucl_partpool:
sum(d2$y_new - d2$ucl_partpool > 0)

head(
  d2[d2$y_new - d2$ucl_partpool > 0,
     c("n", "y", "n_new", "y_new",
       "true_theta", "theta_partpool",
       "ucl_true_theta", "ucl_partpool")]
)

tail(
  d2[d2$y_new - d2$ucl_partpool > 0,
     c("n", "y", "n_new", "y_new",
       "true_theta", "theta_partpool",
       "ucl_true_theta", "ucl_partpool")]
)
```

As analyzed in detail in the
[simulation study](https://jmeydam.github.io/count-anomalies/simulation_study.html),
if we gradually increase the factor from 1 to 8 we will find that the number
of cases exceeding the UCL is similar for the partial-pooling and true-theta 
UCLs, but initially substantially higher for the no-pooling UCLs, as was 
demonstrated here for a factor of 2. The no-pooling UCL performs poorly 
especially when the previously observed count _y_ was 0, leading to an UCL
of 0.5.

The general results are not affected when changing the seed value.

In a realistic scenario it is not possible to assess performance by
comparison with "true" values. The true values of _theta_ are generally 
not known, and the probability distributions assumed for the Bayesian 
hierarchical model (the no-pooling model) may in fact be inappropriate.

On the other hand, in a realistic scenario it is often possible to assess 
performance by investigating individual cases.

## HTML Report

Select data from data frame d (example 1 above) for the report:

```{r}
countcheck_df <- select_for_report(d)
```

Result:

```{r}
str(countcheck_df)
```

We also need a data frame with unit master data.
Here, we just simulate data:

```{r}
units_tmp <- sort(unique(countcheck_df$unit))
unit_df <- data.frame(
  unit = units_tmp,
  unit_name = paste("Unit",
                    units_tmp),
  unit_url = paste0("http://domain/units/",
                    units_tmp,
                    ".html"),
  unit_group_name = paste("Group",
                          rep(1:5,
                              length.out = length(units_tmp)))
)
```

Result:

```{r}
str(unit_df)
```

Generate report as R string:

```{r}
report <- html_report(
  countcheck_list = list(
    list(df = countcheck_df, caption = "KPI 1")
  ),
  unit_df = unit_df,
  title = "Report",
  table_width_px = 500,
  column_headers = c(
    group = "Group",
    count = "Count",
    ucl = "UCL",
    unit = "Unit",
    name = "Name"),
  charset = "utf-8",
  lang = "en",
  home_url = "https://github.com/jmeydam/countcheck")
```

Save HTML report to disk:

```
> sink("report.html")
> cat(report)
> sink()
```

[View HTML report](https://jmeydam.github.io/countcheck/report.html)

<br/><br/>
